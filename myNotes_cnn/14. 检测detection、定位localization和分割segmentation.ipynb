{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要内容：\n",
    "- Semantic segmentation:No object, just pixels\n",
    "- Classification + Localization:single object\n",
    "- Object Detection:Multiple Object\n",
    "- Instance segmentation- Multiple Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 如何在训练中添加层？　\n",
    "lan Goodfellow Net2Net, Network Morphism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 语义分割Semantic Segmentation:Fully Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180313172452003?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Long, Shelhamer, and Darrell, “Fully Convolutional Networks for Semantic Segmentation”, CVPR 2015](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)\n",
    "\n",
    "[Noh et al, “Learning Deconvolution Network for Semantic Segmentation”, ICCV 2015](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Noh_Learning_Deconvolution_Network_ICCV_2015_paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "降采样downsample:用卷积和池化都可以实现～"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上采样upsample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180313173815606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Max Unpooling\"\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180313173948605?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么要采用这样的方案？\n",
    "- 首先全部使用跟原图像一样大小的卷积核，显然会导致参数过多(convolutions at original image resolution will be very expensive).\n",
    "- 二是，我们为什么要做分割？我们希望给予像素预测结果尽可能好，我们想要找到边界，让这些细节体现在预测中，如果我们做最大池化，在特征图中这种不均匀性(heterogeneity)会凸显出来。但在低清晰度(low resoluton image)中你会丢失一些空间信息，你不知道这些信息属于哪里，所以在最大池化后，需要将向量去赤池化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可学习的上采样(Learnable Upsampling): 卷积转置(Transpose Convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180313191237617?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 反向卷积核中的权重参数也是需要学习得到的，比如3x3的卷积核，则有9个参数～输入在这里相当于卷积核的权重,当感受野重合时，取加权和～\n",
    "- 步长是输出和输入中移动距离的比值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们获得了这样的卷积网络。降采样采用stride convolution和pooling,过采样通过transpose convolution和各种unpooling\\unsampling实现，然后利用反向传播端到端(end to end)训练这个网络，用交叉熵衡量基于每个像素的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 分类和定位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多重任务multi-task loss\n",
    "\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180313195432971?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里有两个损失，因此需要给两种损失加上一些权重的超参数，然后进行加权求和。这种超参数很难确定，它会直接影响损失函数的值。\n",
    "- 在实际任务中，也有人这么做，将前面的迁移学习的网络冻结，然后只训练全连接层的网络参数，然后在回过头来调整整个神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 人体姿态估计Human Pose Estimation\n",
    "\n",
    "[Johnson and Everingham, \"Clustered Pose and Nonlinear Appearance Models\n",
    "for Human Pose Estimation\", BMVC 2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180313200259306?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "[Toshev and Szegedy, “DeepPose: Human Pose\n",
    "Estimation via Deep Neural Networks”, CVPR 2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把多任务学习看成一种正则化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Object Detection + Caption = Dense Caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R-CNN\n",
    "- Fast R-CNN\n",
    "- Faster R-CNN\n",
    "- SPP\n",
    "- YOLO/SSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Instance Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask R-CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
