{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PixelRNN and PixelCNN\n",
    "- Variational Autoencoders\n",
    "- Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 监督学习和无监督学习\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315155900849?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "- Clustering\n",
    "- dimensionality reduction\n",
    "- feature learning\n",
    "- density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.生成模型Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315164343369?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要分为两大类：\n",
    "- Explicit density setimation 显示密度估计\n",
    "- Implicit density estimation 隐式密度估计\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315165702616?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PixelRNN and PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315171012077?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在已有的像素分布基础上，去预测下一个像素的分布概率，并选择概率最大的作为当前像素的值。\n",
    "感觉有点类似于训练词向量的语言模型，这里的输入数据是很多图片，相当于语料库，从图片的一个角开始，确定第一个像素的分布，然后以它为基础生成下一个像素的概率分布，使其似然概率最大。具体实现还得看看文献。。\n",
    "\n",
    "[Pixel Recurrent Neural Networks](https://arxiv.org/abs/1601.06759)\n",
    "\n",
    "[Conditional Image Generation with PixelCNN Decoders](https://arxiv.org/abs/1606.05328)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variational Autoencoders(VAE)　变分自编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 首先要了解自动编码器Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315173908704?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过CNN将输入数据X映射到特征Z，那么问题来了，为什么要维度会降低呢？\n",
    "\n",
    "Z用来表示X中最重要的特征，用来捕捉数据中有意义的变化因素的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何学习得到这样的特征表示呢？\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315174339400?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315174607028?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "反向卷积，损失函数为L2损失。类似于语义分割里面的Fully Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练好之后就可以丢掉解码器Decoder了，然后使用训练好的编码器实现特征映射(feature mapping).然后可以用来实现有监督学习的分类模型。\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315175131316?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比有标签的监督学习，当我们只有少量数据有标签时，使用监督学习会很容易造成过拟合。所以对于大量没有标签的数据，可以先用自动编码器训练好编码器，然后使用少量有便签的数据，对编码器进行微调fine-tune。\n",
    "\n",
    "其实很类似于迁移学习，不过迁移学习中的预训练模型都是在有标签的数据下训练得到的。当我们在使用类似的数据集时，也可以用预训练好的模型，来进行fine-tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Variational Autoencoders(VAE)变分编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315191344436?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "直观上讲，z的元素要捕捉的信息是，在训练数据中某种变化因子的多少，可能类似于某种属性的东西。\n",
    "\n",
    "生成模型，即从隐藏变量Z生成数据X:从关于z的先验分布prior中采样。\n",
    "高斯分布是一个对z中每个元素的一种自然的先验假设。在给定z的条件下，x的条件概率分布$P(x|z)$中采样。\n",
    "\n",
    "上述采样过程中，真实的参数是$\\theta*$,有关于先验假设和条件概率分布。我们的目的，就是获得一个生成式来生成模型。真实参数中的这些参数就是我们想要估计得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 那么我们如何表示这个模型呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择一个先验分布p(z),比如Gaussian.\n",
    "- 条件概率(Conditional)p(x|z)很复杂,我们用神经网络来表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.然后如何训练这个模型呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到最大信念网络Fully visible belief network(FVBN),学习参数来使得训练数据的似然likeihood最大.\n",
    "$$p_{\\theta}(x)=\\int p_{\\theta}(z)p_{\\theta}(x|z)dz$$\n",
    "其中$p_{\\theta}(z)$是先验概率分布，$p_{\\theta}(x|z)$是decoder network\n",
    "\n",
    "通过最大化训练数据的似然函数来寻找模型参数。\n",
    "\n",
    "但问题是，z是连续的,所以这个积分很难计算$p(x|z)$对每一个z的积分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.后验概率分布**也很难求：$$p_{\\theta}(z|x)=p_{\\theta}(x|z)p_{\\theta}(z)/p_{\\theta}(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315194734859?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决的办法是**：用一个额外的encoder network编码器$q_{\\phi}(z|x)$来近似表示后验概率$p_{\\theta}(z|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315202334598?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$mu_{z|x},\\sum_{z|x}$分别表示均值和方差。\n",
    "\n",
    "encoder network识别网络:$q_{\\phi}(z|x)$,参数$\\phi$，从z|x~$N(\\mu_{z|x},\\sum_{z|x})$采样得到z\n",
    "\n",
    "decoder network识别网络:$p_{\\theta}(x|z)$,参数$\\theta$，从x|z~$N(\\mu_{x|z},\\sum_{x|z})$采样得到x|z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这就是生成数据的整个流程～"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.计算对数似然：\n",
    "有了encoder\\decoder network,接下来就要简化模型，即计算对数似然概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315211324812?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "看起来有点可怕而已，整个过程推导起来并不难～但要理解左后三个式子的意义。\n",
    "\n",
    "注意这里的值是关于z的期望。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315211524670?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180315211534912?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.模型训练的整个流程："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315212001034?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用解码器encoder network可用来生成数据："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315212012733?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.变分编码器的优缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180315212240778?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 与传统的自动编码器相比，采用了随机分布和采样的思想，这样依赖就能生成数据\n",
    "- 为了训练AVEs,定义一个难处理的密度估计=>推导并优化（变分）下界，变分实际上就是用近似来解决这些。\n",
    "\n",
    "优点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
