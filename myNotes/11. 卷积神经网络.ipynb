{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 卷积神经网络的结构\n",
    "- 为什么要用卷积层？ why convolution？\n",
    "\n",
    "\n",
    "### 1. 卷积神经网络的结构：\n",
    "\n",
    "输入层 --> 卷积层 --> ReLU层 --> 池化层 --> 全连接层\n",
    "\n",
    "\n",
    "### 2. 卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**概述和直观介绍：**\n",
    "首先讨论的是，在没有大脑和生物意义上的神经元之类的比喻下，卷积层到底在计算什么。**卷积层的参数是由一些可学习的滤波器集合构成的**。每个滤波器在空间上（宽度和高度）都比较小，但是深度和输入数据一致。举例来说，卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3（宽高都是5像素，深度是3是因为图像应为颜色通道，所以有3的深度）。在前向传播的时候，让每个滤波器都在输入数据的宽度和高度上滑动（更精确地说是卷积），然后**计算整个滤波器和输入数据任一处的内积**。当滤波器沿着输入数据的宽度和高度滑过后，会生成一个2维的激活图（activation map），激活图给出了在每个空间位置处滤波器的反应。直观地来说，网络会让滤波器学习到当它看到某些类型的视觉特征时就激活，具体的视觉特征可能是某些方位上的边界，或者在第一层上某些颜色的斑点，甚至可以是网络更高层上的蜂巢状或者车轮状图案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 边缘检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ng以边缘检测为例来对此进行了解释：\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180209162657030?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图是简化成2d图的，实际上图像的深度channel为3，滤波器的深度与输入数据一致。\n",
    "上图中的是vertical edge detection，仅仅从数学的角度去卷积，当某一片像素都一样的时候，最后卷积得到的结果都为0，只有在边缘处，左右两边像素本来就不一样，然后左边*1，右边*-1,这样会使得这一片区域像素差距更大。\n",
    "\n",
    "更多的边缘检测可以看看这篇博客[OpenCV边缘检测：Canny算子,Sobel算子,Laplace算子,Scharr滤波器合辑](http://blog.csdn.net/poem_qianmo/article/details/25560901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180209163227194?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这幅图很好的表明的卷积层的过程。filter在输入数据上滑动(卷积)，得到一个二维图。然后有$n_c$个filter，则得到输出数据的深度为$n_c$.\n",
    "\n",
    "可以将每一个人filter看作一个特征检测器（fiter上每个深度的数值其实也是不一样的，所以是3个特征检测器？），如果知道特征如何提取，，比如提取垂直边缘特征，filter的个数以及相应的参数个数也就确定了，无论输入的图片尺寸怎么变化~~这就是卷积神经网络的一个性质：“避免过拟合\" less prone to over fitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 那么卷积层到底有哪些好处？\n",
    "\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180209164319055?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "使用卷积神经网络主要有两个有点：\n",
    "1. **参数共享：**一个特征检测器对图片中的某一块区域适用的话，那么他对图片中的其他区域该特征的检测也是适用的。\n",
    "2. **稀疏连接：**output中某一个像素值的获得只与input里面某一块区域相关。以上图为例，output中左上角的0只取决于input中左上角的9个元素（receptive field）。显然这样是合理的吧~~~如果是全链接呢，input中所有的元素都会与output中的任意一个元素相连，一是这会过拟合吧，二是，这样weight参数就太多太多了。。\n",
    "\n",
    "cs231n note的解释:\n",
    "\n",
    "**参数共享：**用大脑和生物神经元来做比喻，那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出，而该神经元只观察输入数据中的一小部分，并且和空间上左右两边的所有神经元共享参数（因为这些数字都是使用同一个滤波器得到的结果）。将每个数据看作一个神经元,他只和感受野（receptive field）全链接~~~\n",
    "\n",
    "**局部连接：** 在处理图像这样的高维度输入时，让每个神经元都与前一层中的所有神经元进行全连接是不现实的。相反，我们让每个神经元只与输入数据的一个局部区域连接。该连接的空间大小叫做神经元的感受野（receptive field），它的尺寸是一个超参数（其实就是滤波器的空间尺寸）。在深度方向上，这个连接的大小总是和输入量的深度相等。需要再次强调的是，我们对待空间维度（宽和高）与深度维度是不同的：连接在空间（宽高）上是局部的，但是在深度上总是和输入数据的深度一致。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 理解了原理，我们来规定下参数，以便进行数学计算：\n",
    "\n",
    "layer $l$ is a convolution layer:\n",
    "\n",
    "**输入input:** $ n_{H}^{[l-1]}\\cdot n_{W}^{[l-1]}\\cdot n_{c}^{[l-1]}$\n",
    "\n",
    "**过滤器filter以及步长和padding:**\n",
    "\n",
    "$f^{[l]} = filter\\  size$\n",
    "\n",
    "$n_c^{[l]} = number\\  of \\  filters$\n",
    "\n",
    "$p^{[l]} = padding$\n",
    "\n",
    "$s^{[l]} = stride$\n",
    "\n",
    "each filter is ：$f^{[l]}\\cdot f^{[l]} \\cdot n_{c}^{[l-1]}$\n",
    "\n",
    "**偏差bias：**\n",
    "$n_c^{[l]} = (1,1,1,n_c^{[l]})$\n",
    "\n",
    "**输出output:**\n",
    "$n_{H}^{[l]}\\cdot n_{W}^{[l]}\\cdot n_{c}^{[l]}$\n",
    "\n",
    "**so:** \n",
    "\n",
    "$n_{H}^{[l]} = \\dfrac{n_{H}^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1$\n",
    "\n",
    "$n_{W}^{[l]} = \\dfrac{n_{W}^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数总个数：$f^{[l]}\\cdot f^{[l]} \\cdot n_{c}^{[l-1]} \\cdot n_c^{[l]} +n_c^{[l]} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真实案例：[Krizhevsky](http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)构架赢得了2012年的ImageNet挑战，其输入图像的尺寸是[227x227x3]。在第一个卷积层，神经元使用的感受野尺寸(过滤器尺寸)$F=11$,步长$S=4$，不适用零填充$P=0$,卷积层深度(过滤器个数)$K=96$. \n",
    "\n",
    "一个深度切片对应一个过滤器：\n",
    "因为(227-11)/4+1=55，则卷积层的输出体尺寸为[55x55x96]. 55x55x96个神经元中，每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接。就是将深度维度上一个单独的2维切片看做**深度切片（depth slice）**，比如一个数据体尺寸为[55x55x96]的就有96个深度切片，每个尺寸为[55x55]。在每个深度切片上的神经元都使用同样的权重和偏差。在这样的参数共享下，例子中的第一个卷积层就只有96个不同的权重集了，一个权重集对应一个深度切片，共有96x11x11x3=34,848个不同的权重，或34,944个参数（+96个偏差）。在每个深度切片中的55x55个权重使用的都是同样的参数。在反向传播的时候，都要计算每个神经元对它的权重的梯度，但是需要把同一个深度切片上的所有神经元对权重的梯度累加，这样就得到了对共享权重的梯度。这样，每个切片只更新一个权重集。\n",
    "\n",
    "#### 2.5 对参数共享进一步讨论：\n",
    "参数共享的假设是有道理的：如果在图像某些地方探测到一个水平的边界是很重要的，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。所以在卷积层的输出数据体的55x55个不同位置中，就没有必要重新学习去探测一个水平边界了。\n",
    "\n",
    "但有时候参数共享假设可能没有意义，特别是当卷积神经网络的输入图像是一些明确的中心结构时候。这时候我们就应该期望在图片的不同位置学习到完全不同的特征。一个具体的例子就是输入图像是人脸，人脸一般都处于图片中心。你可能期望不同的特征，比如眼睛特征或者头发特征可能（也应该）会在图片的不同位置被学习。在这个例子中，通常就放松参数共享的限制，将层称为局部连接层（Locally-Connected Layer）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![这里写图片描述](http://img.blog.csdn.net/20180209175241173?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "demo:https://cs231n.github.io/assets/conv-demo/index.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6  1x1 convolution\n",
    "\n",
    "![这里写图片描述](http://img.blog.csdn.net/20180209201804732?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcGFueGlhb3hpZQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n",
    "\n",
    "$n_c^{[l+1]} = n_c^{[l]}$  那么1*1 conv起到了非线性化relu的作用\n",
    "\n",
    "$n_c^{[l+1]} > n_c^{[l]}$   增加信道\n",
    "\n",
    "$n_c^{[l+1]} < n_c^{[l]}$   压缩信道的作用；与pooling不同，pooling是压缩图像尺寸。!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. 池化层pooling\n",
    "\n",
    "#### 为什么要做padding？\n",
    "原因有两点：\n",
    "\t1. 经过卷积之后图像缩小了，这意味着肯定有信息丢失了 shrink output\n",
    "\t2. 丢掉的信息更多的是在图像的边界处，因为图像中间的元素会被过滤器不断的重复，而最边上的像素点可能出现一次就没了。。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
