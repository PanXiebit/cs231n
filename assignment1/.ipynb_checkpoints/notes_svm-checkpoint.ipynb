{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_loss_naive(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D, there are C classes, and we operate on minibatches\n",
    "    of N examples.\n",
    "\n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, C) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "      that X[i] has label c, where 0 <= c < C.\n",
    "    - reg: (float) regularization strength\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)  # initialize the gradient as zero\n",
    "    # compute the loss and the gradient\n",
    "    num_classes = W.shape[1]\n",
    "    num_train = X.shape[0]\n",
    "    loss = 0.0\n",
    "    for i in xrange(num_train):\n",
    "        scores = X[i].dot(W)\n",
    "        correct_class_score = scores[y[i]]  # y[i]表示第i个样本的真实标签。score表示其得分\n",
    "        for j in xrange(num_classes): #j表示\n",
    "            if j == y[i]:\n",
    "                continue     # 如果满足，则跳出该for循环。即公式里面，求和时j!=y_{i}\n",
    "            margin = scores[j] - correct_class_score + 1  # note delta = 1\n",
    "            if margin > 0:\n",
    "                loss += margin\n",
    "                dW[:, j] += X[i].T  #矩阵求导\n",
    "                dW[:, y[i]] -= X[i].T\n",
    "\n",
    "            # Right now the loss is a sum over all training examples, but we want it\n",
    "            # to be an average instead so we divide by num_train.\n",
    "    loss /= num_train\n",
    "    dW /= num_train\n",
    "    dW += reg * 2 * W\n",
    "\n",
    "    # Add regularization to the loss.\n",
    "    loss += reg * np.sum(W * W)  # L2 正则化项\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO:                                                                     #\n",
    "    # Compute the gradient of the loss function and store it dW.                #\n",
    "    # Rather that first computing the loss and then computing the derivative,   #\n",
    "    # it may be simpler to compute the derivative at the same time that the     #\n",
    "    # loss is being computed. As a result you may need to modify some of the    #\n",
    "    # code above to compute the gradient.                                       #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个题目主要难点是 Loss 对 W 的偏导数要弄清楚怎么求, 然后就可以程序实现了。 \n",
    "\n",
    "首先看损失函数公式（1）![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中对于某一个样本Xi(shape=(1,D)),与权重W(shape=(D,C))(可以看出所有样本共享参数)，得到其损失函数为Li(shape=(1,C)),反向求导求梯度dW：\n",
    "样本Xi分别与权重W中的每一列Wj相乘，得到对应的损失函数Lij，故dWj分别受Lij的影响。\n",
    "对公式（1）求导：\n",
    "当 j==yi 时： dWyi = -Xi\n",
    "当 j!= yi 时：dWi = Xi\n",
    "(dWj和一个样本xi包含的元素一样多，xi对应位置的分量给对应位置的dWj分量带来贡献）\n",
    "所有样本共享参数，故所有的样本累计求一遍，然后再除以样本总数，并加上正则项，就可以得到我们要求的 dW。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the loss and its gradient at W.\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# Numerically compute the gradient along several randomly chosen dimensions, and\n",
    "# compare them with your analytically computed gradient. The numbers should match\n",
    "# almost exactly along all dimensions.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里涉及到lambda函数中嵌套函数\n",
    "其中在grad_check_sparse函数中，W是函数f的参数，W带入svm_loss_naive函数中得到返回值[0]即loss，loss是关于W的函数，即可用差值法求梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_loss_vectorized(W, X, y, reg):\n",
    "    \"\"\"\n",
    "    Structured SVM loss function, vectorized implementation.\n",
    "\n",
    "    Inputs and outputs are the same as svm_loss_naive.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    num_train = X.shape[0]\n",
    "    dW = np.zeros(W.shape)  # initialize the gradient as zero\n",
    "    #############################################################################\n",
    "    # TODO:                                                                     #\n",
    "    # Implement a vectorized version of the structured SVM loss, storing the    #\n",
    "    # result in loss.                                                           #\n",
    "    #############################################################################\n",
    "    scores = X.dot(W)\n",
    "    correct_class_scores = scores[np.arange(num_train), y].reshape(num_train, 1)\n",
    "    margins = scores - correct_class_scores + 1\n",
    "    margins[margins < 0] = 0\n",
    "    margins[np.arange(num_train), y] = 0\n",
    "    loss = np.sum(margins)  # 所有的超过边界的值的和\n",
    "    loss /= num_train\n",
    "    loss += reg * np.sum(W ** 2)\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "\n",
    "\n",
    "    #############################################################################\n",
    "    # TODO:                                                                     #\n",
    "    # Implement a vectorized version of the gradient for the structured SVM     #\n",
    "    # loss, storing the result in dW.                                           #\n",
    "    #                                                                           #\n",
    "    # Hint: Instead of computing the gradient from scratch, it may be easier    #\n",
    "    # to reuse some of the intermediate values that you used to compute the     #\n",
    "    # loss.                                                                     #\n",
    "    #############################################################################\n",
    "    X_mask = np.zeros(margins.shape)\n",
    "    X_mask[margins > 0] = 1\n",
    "    incorrect_counts = np.sum(X_mask, axis=1)\n",
    "    X_mask[np.arange(num_train), y] = -incorrect_counts\n",
    "    dW = X.T.dot(X_mask)\n",
    "    dW /= num_train\n",
    "    dW += reg  * W\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这题里面有两点需要理解，ndarray[ndarray,list]中间两个参数可以这么用\n",
    "correct_class_scores = scores[np.arange(num_train), y].reshape(num_train, 1)\n",
    "举例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 5 3 8 4]\n",
      " [8 8 2 8 2]\n",
      " [6 1 2 1 2]\n",
      " [7 4 8 1 5]\n",
      " [5 5 3 4 1]]\n",
      "[1 8 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randint(1,9,(5,5))\n",
    "print(a)\n",
    "b = a[np.arange(5),[0,1,2,3,4]]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
